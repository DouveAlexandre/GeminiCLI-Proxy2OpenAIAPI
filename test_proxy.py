#!/usr/bin/env python3
"""
Script de teste para o proxy Gemini-OpenAI
Testa diferentes cenÃ¡rios para identificar problemas no mapeamento
"""

import requests
import json
import time
import sys
from typing import Dict, Any, Optional

class ProxyTester:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer qualquer-valor"  # Como configurado no config.json
        }
    
    def test_models_endpoint(self) -> bool:
        """Testa o endpoint /v1/models"""
        print("ğŸ” Testando endpoint /v1/models...")
        try:
            response = requests.get(f"{self.base_url}/v1/models", headers=self.headers)
            print(f"Status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"Modelos disponÃ­veis: {json.dumps(data, indent=2)}")
                return True
            else:
                print(f"âŒ Erro: {response.status_code} - {response.text}")
                return False
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o: {e}")
            return False
    
    def test_simple_chat(self) -> bool:
        """Testa chat simples sem streaming"""
        print("\nğŸ” Testando chat simples (sem streaming)...")
        
        payload = {
            "model": "gemini-2.5-pro",
            "messages": [
                {"role": "user", "content": "OlÃ¡! Como vocÃª estÃ¡?"}
            ],
            "max_tokens": 100,
            "temperature": 0.7,
            "stream": False
        }
        
        try:
            print(f"Enviando requisiÃ§Ã£o: {json.dumps(payload, indent=2)}")
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            print(f"Status: {response.status_code}")
            print(f"Headers: {dict(response.headers)}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"Resposta: {json.dumps(data, indent=2)}")
                
                # Verificar estrutura da resposta
                if self._validate_openai_response(data):
                    print("âœ… Resposta vÃ¡lida no formato OpenAI")
                    return True
                else:
                    print("âŒ Resposta invÃ¡lida - estrutura incorreta")
                    return False
            else:
                print(f"âŒ Erro: {response.status_code}")
                print(f"Resposta: {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o: {e}")
            return False
    
    def test_streaming_chat(self) -> bool:
        """Testa chat com streaming"""
        print("\nğŸ” Testando chat com streaming...")
        
        payload = {
            "model": "gemini-2.5-pro",
            "messages": [
                {"role": "user", "content": "Conte uma piada curta"}
            ],
            "max_tokens": 150,
            "temperature": 0.8,
            "stream": True
        }
        
        try:
            print(f"Enviando requisiÃ§Ã£o streaming: {json.dumps(payload, indent=2)}")
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                stream=True,
                timeout=30
            )
            
            print(f"Status: {response.status_code}")
            print(f"Headers: {dict(response.headers)}")
            
            if response.status_code == 200:
                print("Recebendo chunks de streaming:")
                chunks_received = 0
                full_content = ""
                
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        print(f"Chunk raw: {line_str}")
                        
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]  # Remove 'data: '
                            
                            if data_str == '[DONE]':
                                print("âœ… Stream finalizado com [DONE]")
                                break
                            
                            try:
                                chunk_data = json.loads(data_str)
                                chunks_received += 1
                                
                                # Extrair conteÃºdo do chunk
                                if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                                    delta = chunk_data['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        full_content += content
                                        print(f"ConteÃºdo do chunk {chunks_received}: '{content}'")
                                
                            except json.JSONDecodeError as e:
                                print(f"âŒ Erro ao decodificar chunk JSON: {e}")
                                print(f"Dados problemÃ¡ticos: {data_str}")
                
                print(f"\nğŸ“Š Resumo do streaming:")
                print(f"Chunks recebidos: {chunks_received}")
                print(f"ConteÃºdo completo: '{full_content}'")
                
                if chunks_received > 0 and full_content:
                    print("âœ… Streaming funcionando corretamente")
                    return True
                else:
                    print("âŒ Streaming com problemas - poucos chunks ou sem conteÃºdo")
                    return False
            else:
                print(f"âŒ Erro: {response.status_code}")
                print(f"Resposta: {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o: {e}")
            return False
    
    def test_with_reasoning(self) -> bool:
        """Testa chat com reasoning habilitado"""
        print("\nğŸ” Testando chat com reasoning...")
        
        payload = {
            "model": "gemini-2.5-pro",
            "messages": [
                {"role": "user", "content": "Resolva: Se um trem viaja a 80 km/h e precisa percorrer 240 km, quanto tempo levarÃ¡?"}
            ],
            "max_tokens": 200,
            "temperature": 0.3,
            "include_reasoning": True,
            "stream": True
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                stream=True,
                timeout=30
            )
            
            if response.status_code == 200:
                reasoning_found = False
                regular_content = ""
                
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data: ') and not line_str.endswith('[DONE]'):
                            data_str = line_str[6:]
                            try:
                                chunk_data = json.loads(data_str)
                                if 'choices' in chunk_data:
                                    delta = chunk_data['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        if content.startswith('<think>'):
                                            reasoning_found = True
                                            print(f"ğŸ§  Reasoning detectado: {content}")
                                        else:
                                            regular_content += content
                            except:
                                pass
                
                print(f"Reasoning encontrado: {reasoning_found}")
                print(f"ConteÃºdo regular: '{regular_content}'")
                return True
            else:
                print(f"âŒ Erro: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o: {e}")
            return False
    
    def test_malformed_request(self) -> bool:
        """Testa requisiÃ§Ã£o malformada"""
        print("\nğŸ” Testando requisiÃ§Ã£o malformada...")
        
        try:
            # JSON invÃ¡lido
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                data="{ invalid json",
                timeout=10
            )
            
            print(f"Status para JSON invÃ¡lido: {response.status_code}")
            
            if response.status_code == 400:
                print("âœ… Proxy rejeitou corretamente JSON invÃ¡lido")
                return True
            else:
                print("âŒ Proxy deveria retornar 400 para JSON invÃ¡lido")
                return False
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o: {e}")
            return False
    
    def _validate_openai_response(self, data: Dict[str, Any]) -> bool:
        """Valida se a resposta estÃ¡ no formato OpenAI correto"""
        required_fields = ['id', 'object', 'created', 'model', 'choices', 'usage']
        
        for field in required_fields:
            if field not in data:
                print(f"âŒ Campo obrigatÃ³rio ausente: {field}")
                return False
        
        if not isinstance(data['choices'], list) or len(data['choices']) == 0:
            print("âŒ Campo 'choices' deve ser uma lista nÃ£o vazia")
            return False
        
        choice = data['choices'][0]
        choice_required = ['index', 'message', 'finish_reason']
        
        for field in choice_required:
            if field not in choice:
                print(f"âŒ Campo obrigatÃ³rio ausente em choice: {field}")
                return False
        
        message = choice['message']
        if 'role' not in message or 'content' not in message:
            print("âŒ Campos obrigatÃ³rios ausentes em message: role, content")
            return False
        
        return True
    
    def run_all_tests(self) -> Dict[str, bool]:
        """Executa todos os testes"""
        print("ğŸš€ Iniciando testes do proxy Gemini-OpenAI")
        print("=" * 60)
        
        results = {}
        
        # Verificar se o servidor estÃ¡ rodando
        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            if response.status_code != 200:
                print("âŒ Servidor nÃ£o estÃ¡ respondendo corretamente")
                return {"server_running": False}
        except:
            print("âŒ Servidor nÃ£o estÃ¡ rodando ou nÃ£o acessÃ­vel")
            print("ğŸ’¡ Certifique-se de que o proxy estÃ¡ rodando com: npm start")
            return {"server_running": False}
        
        # Executar testes
        tests = [
            ("models_endpoint", self.test_models_endpoint),
            ("simple_chat", self.test_simple_chat),
            ("streaming_chat", self.test_streaming_chat),
            ("reasoning_chat", self.test_with_reasoning),
            ("malformed_request", self.test_malformed_request)
        ]
        
        for test_name, test_func in tests:
            print(f"\n{'='*60}")
            try:
                results[test_name] = test_func()
            except Exception as e:
                print(f"âŒ Teste {test_name} falhou com exceÃ§Ã£o: {e}")
                results[test_name] = False
            
            time.sleep(1)  # Pequena pausa entre testes
        
        # Resumo final
        print(f"\n{'='*60}")
        print("ğŸ“Š RESUMO DOS TESTES")
        print("=" * 60)
        
        passed = 0
        total = len(results)
        
        for test_name, result in results.items():
            status = "âœ… PASSOU" if result else "âŒ FALHOU"
            print(f"{test_name:20} | {status}")
            if result:
                passed += 1
        
        print(f"\nResultado: {passed}/{total} testes passaram")
        
        if passed == total:
            print("ğŸ‰ Todos os testes passaram! O proxy estÃ¡ funcionando corretamente.")
        else:
            print("âš ï¸  Alguns testes falharam. Verifique os logs acima para detalhes.")
        
        return results

def main():
    if len(sys.argv) > 1:
        base_url = sys.argv[1]
    else:
        base_url = "http://localhost:11434"
    
    print(f"Testando proxy em: {base_url}")
    
    tester = ProxyTester(base_url)
    results = tester.run_all_tests()
    
    # Exit code baseado nos resultados
    if all(results.values()):
        sys.exit(0)
    else:
        sys.exit(1)

if __name__ == "__main__":
    main()